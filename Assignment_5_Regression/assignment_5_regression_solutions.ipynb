{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 - Regression Solutions\n",
    "This notebook contains solutions for all questions (Q1-Q4) in Lab Assignment 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import load_iris\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q1: Ridge Regression using Gradient Descent Optimization\n",
    "Generate a dataset with at least 7 highly correlated columns and implement Ridge Regression using Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Dataset with Highly Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def generate_correlated_data(n_samples=1000, n_features=7):\n",
    "    \"\"\"Generate a dataset with highly correlated features\"\"\"\n",
    "    base_feature = np.random.randn(n_samples, 1)\n",
    "    \n",
    "    X = np.zeros((n_samples, n_features))\n",
    "    for i in range(n_features):\n",
    "        noise = np.random.randn(n_samples, 1) * 0.3\n",
    "        X[:, i] = (base_feature + noise).flatten()\n",
    "    \n",
    "    true_weights = np.random.randn(n_features, 1) * 2\n",
    "    y = X @ true_weights + np.random.randn(n_samples, 1) * 0.5\n",
    "    y = y.flatten()\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = generate_correlated_data(n_samples=1000, n_features=7)\n",
    "\n",
    "print(f\"Dataset Shape: X = {X.shape}, y = {y.shape}\")\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "corr_matrix = np.corrcoef(X.T)\n",
    "print(pd.DataFrame(corr_matrix.round(3), \n",
    "                   columns=[f'F{i+1}' for i in range(7)],\n",
    "                   index=[f'F{i+1}' for i in range(7)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Implement Ridge Regression Cost Function and Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_cost(X, y, theta, lambda_reg):\n",
    "    \"\"\"Calculate Ridge Regression cost (MSE + L2 penalty)\"\"\"\n",
    "    m = len(y)\n",
    "    predictions = X @ theta\n",
    "    mse = (1/(2*m)) * np.sum((predictions - y)**2)\n",
    "    l2_penalty = (lambda_reg/(2*m)) * np.sum(theta[1:]**2)\n",
    "    return mse + l2_penalty\n",
    "\n",
    "def ridge_gradient_descent(X, y, learning_rate, lambda_reg, n_iterations=1000):\n",
    "    \"\"\"Implement Ridge Regression using Gradient Descent\"\"\"\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    cost_history = []\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "        predictions = X @ theta\n",
    "        errors = predictions - y\n",
    "        gradients = (1/m) * (X.T @ errors)\n",
    "        \n",
    "        reg_term = np.zeros(n)\n",
    "        reg_term[1:] = (lambda_reg/m) * theta[1:]\n",
    "        gradients += reg_term\n",
    "        \n",
    "        theta = theta - learning_rate * gradients\n",
    "        cost = ridge_cost(X, y, theta, lambda_reg)\n",
    "        cost_history.append(cost)\n",
    "    \n",
    "    return theta, cost_history\n",
    "\n",
    "def calculate_r2(y_true, y_pred):\n",
    "    \"\"\"Calculate R-squared score\"\"\"\n",
    "    ss_res = np.sum((y_true - y_pred)**2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(\"Ridge Regression functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test Different Learning Rates and Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and scale data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Add bias term\n",
    "X_train_b = np.c_[np.ones((X_train_scaled.shape[0], 1)), X_train_scaled]\n",
    "X_test_b = np.c_[np.ones((X_test_scaled.shape[0], 1)), X_test_scaled]\n",
    "\n",
    "print(f\"Training set: {X_train_b.shape}\")\n",
    "print(f\"Test set: {X_test_b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "lambda_values = [1e-15, 1e-10, 1e-5, 1e-3, 0, 1, 10, 20]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Testing hyperparameter combinations...\\n\")\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for lam in lambda_values:\n",
    "        try:\n",
    "            theta, cost_history = ridge_gradient_descent(X_train_b, y_train, lr, lam, n_iterations=1000)\n",
    "            \n",
    "            y_train_pred = X_train_b @ theta\n",
    "            y_test_pred = X_test_b @ theta\n",
    "            \n",
    "            train_r2 = calculate_r2(y_train, y_train_pred)\n",
    "            test_r2 = calculate_r2(y_test, y_test_pred)\n",
    "            final_cost = cost_history[-1]\n",
    "            \n",
    "            if not np.isnan(final_cost) and not np.isinf(final_cost):\n",
    "                results.append({\n",
    "                    'learning_rate': lr,\n",
    "                    'lambda': lam,\n",
    "                    'final_cost': final_cost,\n",
    "                    'train_r2': train_r2,\n",
    "                    'test_r2': test_r2\n",
    "                })\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"Tested {len(results)} valid combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "best_by_cost = results_df.loc[results_df['final_cost'].idxmin()]\n",
    "best_by_r2 = results_df.loc[results_df['test_r2'].idxmax()]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BEST PARAMETERS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBy Minimum Cost:\")\n",
    "print(f\"  Learning Rate: {best_by_cost['learning_rate']}\")\n",
    "print(f\"  Lambda: {best_by_cost['lambda']}\")\n",
    "print(f\"  Final Cost: {best_by_cost['final_cost']:.6f}\")\n",
    "print(f\"  Test R2: {best_by_cost['test_r2']:.4f}\")\n",
    "\n",
    "print(f\"\\nBy Maximum R2 Score:\")\n",
    "print(f\"  Learning Rate: {best_by_r2['learning_rate']}\")\n",
    "print(f\"  Lambda: {best_by_r2['lambda']}\")\n",
    "print(f\"  Final Cost: {best_by_r2['final_cost']:.6f}\")\n",
    "print(f\"  Test R2: {best_by_r2['test_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 results\n",
    "print(\"\\nTop 10 Results by Test R2:\")\n",
    "print(results_df.nlargest(10, 'test_r2').to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q2: Hitters Dataset - Linear, Ridge, and LASSO Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Download Hitters dataset or use sample data\n",
    "# Creating sample similar data for demonstration\n",
    "try:\n",
    "    hitters = pd.read_csv('Hitters.csv')\n",
    "except:\n",
    "    # Create synthetic Hitters-like data\n",
    "    np.random.seed(42)\n",
    "    n = 300\n",
    "    hitters = pd.DataFrame({\n",
    "        'AtBat': np.random.randint(100, 600, n),\n",
    "        'Hits': np.random.randint(50, 200, n),\n",
    "        'HmRun': np.random.randint(0, 40, n),\n",
    "        'Runs': np.random.randint(20, 120, n),\n",
    "        'RBI': np.random.randint(20, 120, n),\n",
    "        'Walks': np.random.randint(10, 100, n),\n",
    "        'Years': np.random.randint(1, 20, n),\n",
    "        'CAtBat': np.random.randint(100, 10000, n),\n",
    "        'CHits': np.random.randint(50, 3000, n),\n",
    "        'CHmRun': np.random.randint(0, 400, n),\n",
    "        'CRuns': np.random.randint(20, 1500, n),\n",
    "        'CRBI': np.random.randint(20, 1500, n),\n",
    "        'CWalks': np.random.randint(10, 1000, n),\n",
    "        'League': np.random.choice(['A', 'N'], n),\n",
    "        'Division': np.random.choice(['E', 'W'], n),\n",
    "        'PutOuts': np.random.randint(50, 1000, n),\n",
    "        'Assists': np.random.randint(0, 500, n),\n",
    "        'Errors': np.random.randint(0, 30, n),\n",
    "        'NewLeague': np.random.choice(['A', 'N'], n)\n",
    "    })\n",
    "    # Generate salary based on features\n",
    "    hitters['Salary'] = (hitters['Hits'] * 2 + hitters['HmRun'] * 10 + \n",
    "                         hitters['Years'] * 50 + np.random.randn(n) * 100 + 200)\n",
    "    # Add some null values\n",
    "    null_indices = np.random.choice(n, 20, replace=False)\n",
    "    hitters.loc[null_indices, 'Salary'] = np.nan\n",
    "\n",
    "print(f\"Dataset shape: {hitters.shape}\")\n",
    "print(f\"\\nNull values:\\n{hitters.isnull().sum()[hitters.isnull().sum() > 0]}\")\n",
    "hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle null values\n",
    "hitters_clean = hitters.dropna()\n",
    "print(f\"Shape after removing nulls: {hitters_clean.shape}\")\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in ['League', 'Division', 'NewLeague']:\n",
    "    if col in hitters_clean.columns:\n",
    "        hitters_clean[col] = le.fit_transform(hitters_clean[col])\n",
    "\n",
    "print(\"\\nPreprocessing complete!\")\n",
    "hitters_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Separate Features and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_hitters = hitters_clean.drop('Salary', axis=1)\n",
    "y_hitters = hitters_clean['Salary']\n",
    "\n",
    "# Split data\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(\n",
    "    X_hitters, y_hitters, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_h = StandardScaler()\n",
    "X_train_h_scaled = scaler_h.fit_transform(X_train_h)\n",
    "X_test_h_scaled = scaler_h.transform(X_test_h)\n",
    "\n",
    "print(f\"Training set: {X_train_h_scaled.shape}\")\n",
    "print(f\"Test set: {X_test_h_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Fit Linear, Ridge, and LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train_h_scaled, y_train_h)\n",
    "\n",
    "# Ridge Regression (alpha = 0.5748)\n",
    "ridge_reg = Ridge(alpha=0.5748)\n",
    "ridge_reg.fit(X_train_h_scaled, y_train_h)\n",
    "\n",
    "# LASSO Regression (alpha = 0.5748)\n",
    "lasso_reg = Lasso(alpha=0.5748)\n",
    "lasso_reg.fit(X_train_h_scaled, y_train_h)\n",
    "\n",
    "print(\"All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_linear = linear_reg.predict(X_test_h_scaled)\n",
    "y_pred_ridge = ridge_reg.predict(X_test_h_scaled)\n",
    "y_pred_lasso = lasso_reg.predict(X_test_h_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "models = ['Linear', 'Ridge', 'LASSO']\n",
    "predictions = [y_pred_linear, y_pred_ridge, y_pred_lasso]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison = []\n",
    "for name, y_pred in zip(models, predictions):\n",
    "    mse = mean_squared_error(y_test_h, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_h, y_pred)\n",
    "    comparison.append({'Model': name, 'MSE': mse, 'RMSE': rmse, 'R2': r2})\n",
    "    print(f\"\\n{name} Regression:\")\n",
    "    print(f\"  MSE:  {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  R2:   {r2:.4f}\")\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison)\n",
    "best_model = comparison_df.loc[comparison_df['R2'].idxmax(), 'Model']\n",
    "print(f\"\\nBest Model: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot comparison\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "axes[0].bar(x - width, comparison_df['RMSE'], width, label='RMSE', color='coral')\n",
    "axes[0].bar(x, comparison_df['R2'], width, label='R2', color='steelblue')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(models)\n",
    "axes[0].set_title('Model Comparison')\n",
    "axes[0].legend()\n",
    "\n",
    "# Coefficient comparison\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X_hitters.columns,\n",
    "    'Linear': linear_reg.coef_,\n",
    "    'Ridge': ridge_reg.coef_,\n",
    "    'LASSO': lasso_reg.coef_\n",
    "})\n",
    "\n",
    "coef_df.set_index('Feature')[['Linear', 'Ridge', 'LASSO']].plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Coefficient Comparison')\n",
    "axes[1].legend()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"- Ridge shrinks coefficients but keeps all features\")\n",
    "print(\"- LASSO can set some coefficients to zero (feature selection)\")\n",
    "print(\"- Linear regression may overfit with many correlated features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q3: Cross Validation for Ridge and Lasso (RidgeCV & LassoCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using California Housing as Boston is deprecated\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_housing = housing.data\n",
    "y_housing = housing.target\n",
    "\n",
    "print(f\"Dataset Shape: {X_housing.shape}\")\n",
    "print(f\"Features: {housing.feature_names}\")\n",
    "\n",
    "# Split and scale\n",
    "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(\n",
    "    X_housing, y_housing, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler_cv = StandardScaler()\n",
    "X_train_cv_scaled = scaler_cv.fit_transform(X_train_cv)\n",
    "X_test_cv_scaled = scaler_cv.transform(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RidgeCV - automatically finds best alpha\n",
    "alphas = np.logspace(-6, 6, 100)\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)\n",
    "ridge_cv.fit(X_train_cv_scaled, y_train_cv)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RIDGE CROSS VALIDATION (RidgeCV)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Alpha: {ridge_cv.alpha_:.6f}\")\n",
    "print(f\"Train R2: {ridge_cv.score(X_train_cv_scaled, y_train_cv):.4f}\")\n",
    "print(f\"Test R2: {ridge_cv.score(X_test_cv_scaled, y_test_cv):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCV - automatically finds best alpha\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5, max_iter=10000)\n",
    "lasso_cv.fit(X_train_cv_scaled, y_train_cv)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LASSO CROSS VALIDATION (LassoCV)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Alpha: {lasso_cv.alpha_:.6f}\")\n",
    "print(f\"Train R2: {lasso_cv.score(X_train_cv_scaled, y_train_cv):.4f}\")\n",
    "print(f\"Test R2: {lasso_cv.score(X_test_cv_scaled, y_test_cv):.4f}\")\n",
    "print(f\"\\nNumber of non-zero coefficients: {np.sum(lasso_cv.coef_ != 0)}/{len(lasso_cv.coef_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare RidgeCV vs LassoCV\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: RidgeCV vs LassoCV\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cv_comparison = pd.DataFrame({\n",
    "    'Model': ['RidgeCV', 'LassoCV'],\n",
    "    'Best Alpha': [ridge_cv.alpha_, lasso_cv.alpha_],\n",
    "    'Train R2': [ridge_cv.score(X_train_cv_scaled, y_train_cv), \n",
    "                 lasso_cv.score(X_train_cv_scaled, y_train_cv)],\n",
    "    'Test R2': [ridge_cv.score(X_test_cv_scaled, y_test_cv),\n",
    "                lasso_cv.score(X_test_cv_scaled, y_test_cv)]\n",
    "})\n",
    "print(cv_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q4: Multiclass Logistic Regression (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "print(f\"Dataset Shape: {X_iris.shape}\")\n",
    "print(f\"Classes: {iris.target_names}\")\n",
    "\n",
    "# Split data\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, random_state=42, stratify=y_iris\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_iris = StandardScaler()\n",
    "X_train_iris_scaled = scaler_iris.fit_transform(X_train_iris)\n",
    "X_test_iris_scaled = scaler_iris.transform(X_test_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step One-vs-Rest Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "\n",
    "def logistic_cost(X, y, theta):\n",
    "    \"\"\"Logistic regression cost function\"\"\"\n",
    "    m = len(y)\n",
    "    h = sigmoid(X @ theta)\n",
    "    epsilon = 1e-15\n",
    "    cost = -(1/m) * np.sum(y * np.log(h + epsilon) + (1 - y) * np.log(1 - h + epsilon))\n",
    "    return cost\n",
    "\n",
    "def logistic_gradient_descent(X, y, learning_rate=0.1, n_iterations=1000):\n",
    "    \"\"\"Train logistic regression using gradient descent\"\"\"\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        h = sigmoid(X @ theta)\n",
    "        gradient = (1/m) * (X.T @ (h - y))\n",
    "        theta = theta - learning_rate * gradient\n",
    "    \n",
    "    return theta\n",
    "\n",
    "print(\"Logistic regression functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-vs-Rest implementation\n",
    "classes = np.unique(y_train_iris)\n",
    "n_classes = len(classes)\n",
    "\n",
    "# Add bias term\n",
    "X_train_b = np.c_[np.ones((X_train_iris_scaled.shape[0], 1)), X_train_iris_scaled]\n",
    "X_test_b = np.c_[np.ones((X_test_iris_scaled.shape[0], 1)), X_test_iris_scaled]\n",
    "\n",
    "# Train one classifier per class\n",
    "classifiers = {}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING ONE-VS-REST CLASSIFIERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for c in classes:\n",
    "    # Create binary labels (class c vs all others)\n",
    "    y_binary = (y_train_iris == c).astype(int)\n",
    "    \n",
    "    # Train classifier\n",
    "    theta = logistic_gradient_descent(X_train_b, y_binary, learning_rate=0.5, n_iterations=2000)\n",
    "    classifiers[c] = theta\n",
    "    \n",
    "    # Training accuracy for this classifier\n",
    "    train_pred = (sigmoid(X_train_b @ theta) >= 0.5).astype(int)\n",
    "    train_acc = np.mean(train_pred == y_binary)\n",
    "    print(f\"Class {c} ({iris.target_names[c]}): Training Accuracy = {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using One-vs-Rest\n",
    "def predict_ovr(X, classifiers):\n",
    "    \"\"\"Predict using One-vs-Rest strategy\"\"\"\n",
    "    probabilities = np.zeros((X.shape[0], len(classifiers)))\n",
    "    \n",
    "    for c, theta in classifiers.items():\n",
    "        probabilities[:, c] = sigmoid(X @ theta)\n",
    "    \n",
    "    return np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = predict_ovr(X_train_b, classifiers)\n",
    "y_test_pred = predict_ovr(X_test_b, classifiers)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS - ONE-VS-REST MULTICLASS LOGISTIC REGRESSION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining Accuracy: {accuracy_score(y_train_iris, y_train_pred):.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test_iris, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_iris, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.title('Confusion Matrix - One-vs-Rest Logistic Regression')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with sklearn implementation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON WITH SKLEARN IMPLEMENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sklearn_ovr = LogisticRegression(multi_class='ovr', max_iter=2000)\n",
    "sklearn_ovr.fit(X_train_iris_scaled, y_train_iris)\n",
    "\n",
    "print(f\"\\nSklearn OvR Accuracy: {sklearn_ovr.score(X_test_iris_scaled, y_test_iris):.4f}\")\n",
    "print(f\"Custom OvR Accuracy: {accuracy_score(y_test_iris, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "- **Q1**: Implemented Ridge Regression from scratch using Gradient Descent with hyperparameter tuning\n",
    "- **Q2**: Compared Linear, Ridge, and LASSO regression on Hitters dataset\n",
    "- **Q3**: Used RidgeCV and LassoCV for automatic alpha selection with cross-validation\n",
    "- **Q4**: Implemented Multiclass Logistic Regression using One-vs-Rest strategy from scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
