{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 8 - SVM (Support Vector Machine) Solutions\n",
    "This notebook contains solutions for all questions in the SVM Lab Assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, classification_report)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 1: Iris Dataset - Comparing SVM Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "print(f\"Iris Dataset Shape: {X_iris.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_iris))}\")\n",
    "print(f\"Class names: {iris.target_names}\")\n",
    "print(f\"Feature names: {iris.feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (80:20)\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, random_state=42, stratify=y_iris\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train_iris.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test_iris.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM with Different Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define kernels to test\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "kernel_results = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training SVM with {kernel.upper()} kernel\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Create and train SVM model\n",
    "    if kernel == 'poly':\n",
    "        svm_model = SVC(kernel=kernel, degree=3, random_state=42)\n",
    "    else:\n",
    "        svm_model = SVC(kernel=kernel, random_state=42)\n",
    "\n",
    "    svm_model.fit(X_train_iris, y_train_iris)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = svm_model.predict(X_test_iris)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_iris, y_pred)\n",
    "    precision = precision_score(y_test_iris, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test_iris, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test_iris, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_test_iris, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    kernel_results[kernel] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    print(f\"\\nConfusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for all kernels\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle('Confusion Matrices for Different SVM Kernels (Iris Dataset)', fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, kernel in enumerate(kernels):\n",
    "    cm = kernel_results[kernel]['confusion_matrix']\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "                xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "    axes[idx].set_title(f'{kernel.upper()} Kernel\\nAccuracy: {kernel_results[kernel][\"accuracy\"]:.4f}')\n",
    "    axes[idx].set_ylabel('True Label')\n",
    "    axes[idx].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('iris_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all kernels\n",
    "print(f\"{'='*60}\")\n",
    "print(\"COMPARISON OF ALL KERNELS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Kernel': kernels,\n",
    "    'Accuracy': [kernel_results[k]['accuracy'] for k in kernels],\n",
    "    'Precision': [kernel_results[k]['precision'] for k in kernels],\n",
    "    'Recall': [kernel_results[k]['recall'] for k in kernels],\n",
    "    'F1-Score': [kernel_results[k]['f1_score'] for k in kernels]\n",
    "})\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Identify best kernel\n",
    "best_kernel = max(kernel_results.items(), key=lambda x: x[1]['accuracy'])[0]\n",
    "print(f\"\\nBest Performing Kernel: {best_kernel.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(kernels))\n",
    "width = 0.2\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "colors = ['steelblue', 'coral', 'green', 'purple']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [kernel_results[k][metric.lower().replace('-', '_')] for k in kernels]\n",
    "    ax.bar(x + i*width, values, width, label=metric, color=colors[i])\n",
    "\n",
    "ax.set_xlabel('Kernel', fontweight='bold')\n",
    "ax.set_ylabel('Score', fontweight='bold')\n",
    "ax.set_title('Performance Comparison of SVM Kernels on Iris Dataset', fontweight='bold')\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels([k.upper() for k in kernels])\n",
    "ax.legend()\n",
    "ax.set_ylim([0.9, 1.01])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('iris_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 2: Effect of Feature Scaling on SVM Performance\n",
    "**Dataset: Breast Cancer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Breast Cancer dataset\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X_cancer = cancer.data\n",
    "y_cancer = cancer.target\n",
    "\n",
    "print(f\"Breast Cancer Dataset Shape: {X_cancer.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_cancer))}\")\n",
    "print(f\"Class names: {cancer.target_names}\")\n",
    "print(f\"Number of features: {X_cancer.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature statistics to demonstrate different scales\n",
    "print(f\"\\nFeature Statistics (showing scale differences):\")\n",
    "feature_stats = pd.DataFrame({\n",
    "    'Feature': cancer.feature_names[:5],\n",
    "    'Mean': X_cancer[:, :5].mean(axis=0),\n",
    "    'Std': X_cancer[:, :5].std(axis=0),\n",
    "    'Min': X_cancer[:, :5].min(axis=0),\n",
    "    'Max': X_cancer[:, :5].max(axis=0)\n",
    "})\n",
    "print(feature_stats.to_string(index=False))\n",
    "print(\"... (and 25 more features with varying scales)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(\n",
    "    X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train_cancer.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test_cancer.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) SVM WITHOUT Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*60}\")\n",
    "print(\"A) SVM (RBF Kernel) WITHOUT Feature Scaling\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Train SVM without scaling\n",
    "svm_no_scale = SVC(kernel='rbf', random_state=42)\n",
    "svm_no_scale.fit(X_train_cancer, y_train_cancer)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_no_scale = svm_no_scale.predict(X_train_cancer)\n",
    "y_test_pred_no_scale = svm_no_scale.predict(X_test_cancer)\n",
    "\n",
    "# Calculate metrics\n",
    "train_acc_no_scale = accuracy_score(y_train_cancer, y_train_pred_no_scale)\n",
    "test_acc_no_scale = accuracy_score(y_test_cancer, y_test_pred_no_scale)\n",
    "\n",
    "print(f\"\\nPerformance WITHOUT Scaling:\")\n",
    "print(f\"  Training Accuracy: {train_acc_no_scale:.4f}\")\n",
    "print(f\"  Testing Accuracy:  {test_acc_no_scale:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix (Without Scaling):\")\n",
    "cm_no_scale = confusion_matrix(y_test_cancer, y_test_pred_no_scale)\n",
    "print(cm_no_scale)\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_cancer, y_test_pred_no_scale, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) SVM WITH Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*60}\")\n",
    "print(\"B) SVM (RBF Kernel) WITH Feature Scaling (StandardScaler)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_cancer)\n",
    "X_test_scaled = scaler.transform(X_test_cancer)\n",
    "\n",
    "print(f\"\\nAfter scaling - Sample feature statistics:\")\n",
    "scaled_stats = pd.DataFrame({\n",
    "    'Feature': cancer.feature_names[:5],\n",
    "    'Mean': X_train_scaled[:, :5].mean(axis=0).round(4),\n",
    "    'Std': X_train_scaled[:, :5].std(axis=0).round(4),\n",
    "})\n",
    "print(scaled_stats.to_string(index=False))\n",
    "print(\"(All features now have mean = 0 and std = 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM with scaling\n",
    "svm_with_scale = SVC(kernel='rbf', random_state=42)\n",
    "svm_with_scale.fit(X_train_scaled, y_train_cancer)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_with_scale = svm_with_scale.predict(X_train_scaled)\n",
    "y_test_pred_with_scale = svm_with_scale.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "train_acc_with_scale = accuracy_score(y_train_cancer, y_train_pred_with_scale)\n",
    "test_acc_with_scale = accuracy_score(y_test_cancer, y_test_pred_with_scale)\n",
    "\n",
    "print(f\"\\nPerformance WITH Scaling:\")\n",
    "print(f\"  Training Accuracy: {train_acc_with_scale:.4f}\")\n",
    "print(f\"  Testing Accuracy:  {test_acc_with_scale:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix (With Scaling):\")\n",
    "cm_with_scale = confusion_matrix(y_test_cancer, y_test_pred_with_scale)\n",
    "print(cm_with_scale)\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_cancer, y_test_pred_with_scale, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Comparison and Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*60}\")\n",
    "print(\"COMPARISON: WITH vs WITHOUT FEATURE SCALING\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Without Scaling', 'With Scaling'],\n",
    "    'Training Accuracy': [train_acc_no_scale, train_acc_with_scale],\n",
    "    'Testing Accuracy': [test_acc_no_scale, test_acc_with_scale],\n",
    "    'Improvement': [0, test_acc_with_scale - test_acc_no_scale]\n",
    "})\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(f\"\\nAccuracy Improvement: {(test_acc_with_scale - test_acc_no_scale)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Plot 1: Accuracy Comparison\n",
    "x_axis = np.arange(2)\n",
    "width = 0.35\n",
    "train_accs = [train_acc_no_scale, train_acc_with_scale]\n",
    "test_accs = [test_acc_no_scale, test_acc_with_scale]\n",
    "\n",
    "axes[0].bar(x_axis - width/2, train_accs, width, label='Training Accuracy', color='skyblue')\n",
    "axes[0].bar(x_axis + width/2, test_accs, width, label='Testing Accuracy', color='coral')\n",
    "axes[0].set_xlabel('Model', fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy', fontweight='bold')\n",
    "axes[0].set_title('Accuracy Comparison', fontweight='bold')\n",
    "axes[0].set_xticks(x_axis)\n",
    "axes[0].set_xticklabels(['Without Scaling', 'With Scaling'])\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim([0.85, 1.0])\n",
    "\n",
    "# Plot 2: Confusion Matrix without scaling\n",
    "sns.heatmap(cm_no_scale, annot=True, fmt='d', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=cancer.target_names, yticklabels=cancer.target_names)\n",
    "axes[1].set_title(f'Without Scaling\\nAccuracy: {test_acc_no_scale:.4f}', fontweight='bold')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "# Plot 3: Confusion Matrix with scaling\n",
    "sns.heatmap(cm_with_scale, annot=True, fmt='d', cmap='Greens', ax=axes[2],\n",
    "            xticklabels=cancer.target_names, yticklabels=cancer.target_names)\n",
    "axes[2].set_title(f'With Scaling\\nAccuracy: {test_acc_with_scale:.4f}', fontweight='bold')\n",
    "axes[2].set_ylabel('True Label')\n",
    "axes[2].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('breast_cancer_scaling_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion: Effect of Feature Scaling on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*70}\")\n",
    "print(\"DISCUSSION: EFFECT OF FEATURE SCALING ON SVM PERFORMANCE\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "1. WHY SCALING MATTERS FOR SVM:\n",
    "   - SVMs use distance-based computations to find the optimal hyperplane\n",
    "   - Features with larger scales dominate the distance calculations\n",
    "   - Without scaling, features with larger ranges have disproportionate influence\n",
    "   - The RBF kernel computes: exp(-gamma * ||x - y||^2)\n",
    "   - Unscaled features make this calculation unstable and biased\n",
    "\n",
    "2. OBSERVED RESULTS:\n",
    "   - Without scaling: Training Acc = {train_acc_no_scale:.4f}, Testing Acc = {test_acc_no_scale:.4f}\n",
    "   - With scaling: Training Acc = {train_acc_with_scale:.4f}, Testing Acc = {test_acc_with_scale:.4f}\n",
    "   - Improvement: {(test_acc_with_scale - test_acc_no_scale)*100:.2f}%\n",
    "\n",
    "3. IMPACT ON THE BREAST CANCER DATASET:\n",
    "   - The dataset has features with vastly different scales\n",
    "   - Example: 'mean radius' (6-28) vs 'worst concave points' (0-0.3)\n",
    "   - Without scaling, high-magnitude features dominate\n",
    "   - Scaling ensures all features contribute proportionally\n",
    "\n",
    "4. STANDARDSCALER EFFECT:\n",
    "   - Transforms each feature to have mean = 0 and std = 1\n",
    "   - All features now contribute equally to distance calculations\n",
    "   - Improves convergence and model performance\n",
    "   - Essential for RBF and polynomial kernels\n",
    "\n",
    "5. BEST PRACTICES:\n",
    "   - ALWAYS use feature scaling for SVM (especially with RBF/polynomial kernels)\n",
    "   - StandardScaler is most common for SVM\n",
    "   - Fit scaler only on training data to avoid data leakage\n",
    "   - Apply same transformation to test data\n",
    "\n",
    "6. CONCLUSION:\n",
    "   Feature scaling is CRITICAL for SVM performance. It ensures fair contribution\n",
    "   from all features and significantly improves model accuracy and generalization.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "- **Q1**: Compared SVM performance with Linear, Polynomial, and RBF kernels on Iris dataset\n",
    "- **Q2**: Demonstrated the critical importance of feature scaling for SVM on Breast Cancer dataset\n",
    "- **Key Takeaways**: \n",
    "  - RBF kernel often performs best for non-linear problems\n",
    "  - Feature scaling is essential for SVM, especially with RBF kernel\n",
    "  - StandardScaler ensures all features contribute equally"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
